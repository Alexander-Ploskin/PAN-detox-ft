defaults:
  - model : mT5
  - tokenizer : mT5
  - peft : lora
  - training_args: seq2seq
  - trainer : seq2seq
  
seed: 42
device: '0'
ds_list : ['textdetox/multilingual_paradetox', 's-nlp/paradetox', 's-nlp/ru_paradetox', 'textdetox/uk_paradetox', 'textdetox/es_paradetox', 'data/mt0_detox_full_data', 'data/nikita_sushko']
use_adapter : False